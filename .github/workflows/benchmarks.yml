name: Performance Benchmarks

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  # Allow manual trigger
  workflow_dispatch:

jobs:
  benchmark:
    name: Run Benchmarks
    runs-on: macos-14

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Swift
        uses: swift-actions/setup-swift@v2
        with:
          swift-version: '6.0'

      - name: Build
        run: swift build -c release

      - name: Run Performance Benchmarks
        run: |
          # Run benchmarks and capture output
          swift test --filter PerformanceBenchmarkTests -c release 2>&1 | tee benchmark-output.txt

          # Extract timing information
          echo "## Benchmark Results" > benchmark-results.md
          echo "" >> benchmark-results.md
          echo "### Thread Listing Performance" >> benchmark-results.md
          grep -E "testThreadListing.*average:" benchmark-output.txt >> benchmark-results.md || true
          echo "" >> benchmark-results.md
          echo "### Thread Detection Performance" >> benchmark-results.md
          grep -E "testThread(IdDetection|Processing|Metadata).*average:" benchmark-output.txt >> benchmark-results.md || true
          echo "" >> benchmark-results.md
          echo "### Sync Performance with Threading" >> benchmark-results.md
          grep -E "testSync.*average:|testIncrementalSync.*average:" benchmark-output.txt >> benchmark-results.md || true
          echo "" >> benchmark-results.md
          echo "### Large Scale Benchmarks" >> benchmark-results.md
          grep -E "testLarge.*average:|testThread.*Scalability.*average:" benchmark-output.txt >> benchmark-results.md || true

      - name: Upload Benchmark Results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            benchmark-output.txt
            benchmark-results.md

      - name: Comment PR with Benchmark Results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let results = '';
            try {
              results = fs.readFileSync('benchmark-results.md', 'utf8');
            } catch (e) {
              results = 'Benchmark results could not be read.';
            }

            const body = `## Performance Benchmark Results\n\n${results}\n\n*Generated by CI on ${new Date().toISOString()}*`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

  benchmark-comparison:
    name: Compare Benchmarks
    runs-on: macos-14
    if: github.event_name == 'pull_request'
    needs: benchmark

    steps:
      - name: Download current benchmark results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results
          path: current-results

      - name: Checkout main branch for baseline
        uses: actions/checkout@v4
        with:
          ref: main
          path: baseline

      - name: Setup Swift
        uses: swift-actions/setup-swift@v2
        with:
          swift-version: '6.0'

      - name: Run Baseline Benchmarks
        working-directory: baseline
        run: |
          swift build -c release
          swift test --filter PerformanceBenchmarkTests -c release 2>&1 | tee ../baseline-output.txt || true

      - name: Compare Results
        run: |
          echo "## Benchmark Comparison (PR vs main)" > comparison.md
          echo "" >> comparison.md
          echo "### Current PR Results" >> comparison.md
          cat current-results/benchmark-results.md >> comparison.md || echo "No current results" >> comparison.md
          echo "" >> comparison.md
          echo "### Baseline (main) Results" >> comparison.md
          grep -E "average:" baseline-output.txt >> comparison.md || echo "No baseline results" >> comparison.md

      - name: Upload Comparison
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-comparison
          path: comparison.md
